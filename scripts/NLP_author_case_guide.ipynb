{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Author Classification Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original context:\n",
    "\n",
    "*Dear colleagues,*\n",
    "\n",
    "*As you know, NLP is a very useful skill in a data scientist toolbox.*\n",
    "*You have had the opportunity to discover this during a social Thursday, now it is time to rise and shine !*\n",
    "\n",
    "*To this end, we will be hosting a case ~~competition~~ training so that everybody can experience this ~~wonderful and life-changing experiment~~ that is classifying text.*\n",
    "\n",
    "This is my go at the challenge where we need to classify a (multiple) sentence(s) to an author :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import base packages\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "proj_dir = os.path.abspath(os.path.join(os.path.dirname(globals()['_dh'][0])))\n",
    "sys.path.append(proj_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you will be modifying the packages\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import local packages\n",
    "from src.config import Config\n",
    "from src.data import construct_training_dataframe\n",
    "from src.apply import apply_fastai_model, apply_fastai_model_on_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup config\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data cleaning from the original files take some time. If you want to save it, you can download the pre-cleanded dataset from a this [sharepoint link](https://agilytic-my.sharepoint.com/:x:/g/personal/jerome_agilytic_be/EcqMEgTAYW9IhOI-SBnyGg8BU80M7aENcMk_55Y8d8Snvw?e=ZxMXqc), and save it in the location: `./data/interim/` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file exists\n",
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "#Clean input data if not done or downloaded yet\n",
    "raw_data_directory = '{}training/'.format(config.get_raw_data_path()) #default, change if necessary\n",
    "training_df_path = '{}training.csv'.format(config.get_interim_data_path()) #default, change if necessary\n",
    "\n",
    "if os.path.isfile(training_df_path):\n",
    "    print('Training file exists')\n",
    "else:\n",
    "    print('Creating new dataframe from directory, this can take a while')\n",
    "    construct_training_dataframe(directory=raw_data_directory)\n",
    "    \n",
    "#Load data\n",
    "training_df = pd.read_csv(training_df_path)\n",
    "print('Data loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's look at the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyze the distribution of the target in 'author' column.\n",
    "\n",
    "There are three authors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df['author'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are distributed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(training_df['author'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do a basic analysis of the text lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df['text_length'] = training_df['text'].str.len()\n",
    "training_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Describe for every author:\n",
    "for author in training_df['author'].unique():\n",
    "    print('Analysis for {}:'.format(author))\n",
    "    print(training_df[training_df['author']==author].describe())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the means are relatively similar, but that there are some outliers in text length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "bplot = sns.boxplot(y='text_length', \n",
    "                    x='author', \n",
    "                    data=training_df, \n",
    "                    width=0.5,\n",
    "                    palette=\"colorblind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different modelling techniques were tried out:\n",
    "\n",
    "For features:\n",
    "- Tfidf \n",
    "- Count vectors\n",
    "\n",
    "Combined with these algorithms:\n",
    "- Logistic Regression \n",
    "- Ranom forests\n",
    "- Multinomial Naive Bayes\n",
    "\n",
    "The results varied between 70% and 84% accuracy on a held out test set\n",
    "\n",
    "**What worked best:**\n",
    "In the end I opted for a deep learning model based on Transfer Learning, using the [Fastai libray](https://www.fast.ai/)\n",
    " library.\n",
    " \n",
    "Fastai is a library built on top of pytorch, aiming at easily applying state of the art deep learning techniques\n",
    "\n",
    "This particalar model was trained using ULM_fit model for transfer learning language learned from millions of wikipedia pages. \n",
    "\n",
    "**The end result was 86% accuracy on the test set**\n",
    "\n",
    "Because it is ressource intensive, I used Google Colab for free GPU power. See the script in ./scripts/train_ulm_fit.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now apply the model using the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_fastai_model_on_sentence('Idris was very content')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to apply the model to a dataframe\n",
    "\n",
    "But without GPU this can be rather slow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = training_df_path\n",
    "max_number_of_rows = 10\n",
    "apply_fastai_model(input_path, max_number_of_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the run on the whole dataset, but it is slow (+-40 minutes for 20k lines):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                               text author\n",
      "0   1  Idris was well content with this resolve of mi...    MWS\n",
      "1   2  I was faint, even fainter than the hateful mod...    HPL\n",
      "2   3  Above all, I burn to know the incidents of you...    EAP\n",
      "3   4  He might see, perhaps, one or two points with ...    EAP\n",
      "4   5  All obeyed the Lord Protector of dying England...    MWS\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.9653675231138581\n"
     ]
    }
   ],
   "source": [
    "input_path = training_df_path\n",
    "result = apply_fastai_model(input_path)\n",
    "\n",
    "y_real = training_df['author']\n",
    "predicted = result['prediction']\n",
    "print(\"Model Accuracy:\",metrics.accuracy_score(y_real, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to industrialize the model, an api was made. \n",
    "This way it can be run on a server, with GPU if it nees to handle large datasets or with CPU if it is the occasional request\n",
    "\n",
    "To run it:\n",
    "1. Check the adress and port in the config file: `./config/config.yml`\n",
    "2. Open Anaconda prompt: activate nlp_author_case\n",
    "3. Go to the root folder of this project\n",
    "4. Run `python ./src/api.py`\n",
    "\n",
    "For now it only classifies sentences using a url similar to http://localhost:5000/sentence?sentence=%22Idris%20was%20very%20content%22\n",
    "\n",
    "If it does not responds, your antivirus (like F-secure) sometimes blocks certain port."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any questions, don't hesitate to contact me, Jérôme Belpaire, at jerome@agilytic.be"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('nlp_author_case': conda)",
   "language": "python",
   "name": "python36764bitnlpauthorcaseconda4eac93e7321846e7b40818430d1a5700"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
